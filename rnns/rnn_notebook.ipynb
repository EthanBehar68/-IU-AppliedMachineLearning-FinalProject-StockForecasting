{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3613jvsc74a57bd09877b9d49ccc7dbf40aead0404d31c44095faccd031bd07272a835057851d67a",
   "display_name": "Python 3.6.13 64-bit ('p556fp': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "9877b9d49ccc7dbf40aead0404d31c44095faccd031bd07272a835057851d67a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### File Organization ###\n",
    "# Imports\n",
    "# RNN models classes\n",
    "    # Simple RNN\n",
    "    # Groovy (5 layer GRU model)\n",
    "    # Loovy (5 layer LSTM model)\n",
    "    # Super Groovy (8 layer GRU model)\n",
    "    # Super Loovy (8 layer LSTM model)\n",
    "# Graph plotting method\n",
    "# Hyperparameters\n",
    "# Data prep - get data from fastquant\n",
    "# Data prep - helper methods and variables\n",
    "# Train, predict methods\n",
    "# Training/Predict Models\n",
    "    # Simple RNN Apple - High column only\n",
    "    # Groovy Apple - High column only\n",
    "    # Loovy Apple - High column only\n",
    "    # Super Groovy Apple - High column only\n",
    "    # Super Loovy Apple - High column only\n",
    "    # Simple RNN IBM - High column only\n",
    "    # Groovy IBM - High column only\n",
    "    # Loovy IBM - High column only\n",
    "    # Super Groovy IBM - High column only\n",
    "    # Super Loovy IBM - High column only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastquant import get_stock_data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN, GRU, LSTM, Dropout\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build SimpleRNN Model\n",
    "\n",
    "# 3 SimpleRNN layers with 32 inputs. Returns full sequence.\n",
    "# 1 SimpleRNN layer with 32 inputs. Does not return full sequence\n",
    "# 1 Dense layer with 1 input. \n",
    "# input -> 32 -> 32 -> 32 -> 32noFS -> 1\n",
    "# Kernel Initializer: Glorot Uniform\n",
    "# Recurrent Initializer: Orthogonal\n",
    "# Bias Initializer: Zeross\n",
    "\n",
    "# Builds a new instance of Simple RNN and scaler (if needed)\n",
    "def build_simple_rnn(useDropout = True):\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(32, return_sequences=True, activation=activation_funct))\n",
    "    if useDropout: model.add(Dropout(dropout))\n",
    "    model.add(SimpleRNN(32, return_sequences=True, activation=activation_funct))\n",
    "    if useDropout: model.add(Dropout(dropout))\n",
    "    model.add(SimpleRNN(32, return_sequences=True, activation=activation_funct))\n",
    "    if useDropout: model.add(Dropout(dropout))\n",
    "    model.add(SimpleRNN(32, return_sequences=False, activation=activation_funct))\n",
    "    model.add(Dense(1, activation=activation_funct))\n",
    "\n",
    "    optimizer = RMSprop(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss=loss)\n",
    "\n",
    "    return model, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Groovy Model\n",
    "\n",
    "# 3 GRU layers with 50 inputs. Returns full sequence\n",
    "# 1 GRU layer with 50 inputs. Does not return full sequence\n",
    "# 1 Dense layer with 1 input.\n",
    "# input -> 50 -> 50 -> 50 -> 50noFS ->1\n",
    "# Kernel Initializer: Glorot Uniform\n",
    "# Recurrent Initializer: Orthogonal\n",
    "# Bias Initializer: Zeros\n",
    "\n",
    "def build_groovy(useDropout = True):\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(GRU(50, return_sequences=True, activation=activation_funct))\n",
    "    if useDropout: model.add(Dropout(dropout))\n",
    "    model.add(GRU(50, return_sequences=True, activation=activation_funct))\n",
    "    if useDropout: model.add(Dropout(dropout))\n",
    "    model.add(GRU(50, return_sequences=True, activation=activation_funct))\n",
    "    if useDropout: model.add(Dropout(dropout))\n",
    "    model.add(GRU(50, return_sequences=False, activation=activation_funct))\n",
    "    model.add(Dense(1, activation=activation_funct))\n",
    "\n",
    "    optimizer = RMSprop(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss=loss)\n",
    "\n",
    "    return model, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Loovy Model\n",
    "\n",
    "# 3 LSTM layers with 50 inputs. Returns full sequence\n",
    "# 1 LSTM layer with 50 inputs. Does not return full sequence\n",
    "# 1 Dense layer with 1 input.\n",
    "# input -> 50 -> 50 -> 50 -> 50noFS ->1\n",
    "# Kernel Initializer: Glorot Uniform\n",
    "# Recurrent Initializer: Orthogonal\n",
    "# Bias Initializer: Zeros\n",
    "\n",
    "def build_loovy(useDropout = True):\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, return_sequences=True, activation=activation_funct))\n",
    "    if useDropout: model.add(Dropout(dropout))\n",
    "    model.add(LSTM(50, return_sequences=True, activation=activation_funct))\n",
    "    if useDropout: model.add(Dropout(dropout))\n",
    "    model.add(LSTM(50, return_sequences=True, activation=activation_funct))\n",
    "    if useDropout: model.add(Dropout(dropout))\n",
    "    model.add(LSTM(50, return_sequences=False, activation=activation_funct))\n",
    "    model.add(Dense(1, activation=activation_funct))\n",
    "\n",
    "    optimizer = RMSprop(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss=loss)\n",
    "\n",
    "    return model, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build SuperGroovy Model\n",
    "\n",
    "# 6 GRU layers with 50 inputs. Returns full sequence\n",
    "# 1 GRU layer with 50 inputs. Does not return full sequence\n",
    "# 1 Dense layer with 1 input.\n",
    "# input -> 50 -> 50 -> 50 -> 50noFS ->1\n",
    "# Kernel Initializer: Glorot Uniform\n",
    "# Recurrent Initializer: Orthogonal\n",
    "# Bias Initializer: Zeros\n",
    "\n",
    "def build_super_groovy(useDropout = True):\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(GRU(50, return_sequences=True, activation=activation_funct))\n",
    "    if useDropout: model.add(Dropout(dropout))\n",
    "    model.add(GRU(50, return_sequences=True, activation=activation_funct))\n",
    "    if useDropout: model.add(Dropout(dropout))\n",
    "    model.add(GRU(50, return_sequences=True, activation=activation_funct))\n",
    "    if useDropout: model.add(Dropout(dropout))\n",
    "    model.add(GRU(50, return_sequences=True, activation=activation_funct))\n",
    "    if useDropout: model.add(Dropout(dropout))\n",
    "    model.add(GRU(50, return_sequences=True, activation=activation_funct))\n",
    "    if useDropout: model.add(Dropout(dropout))\n",
    "    model.add(GRU(50, return_sequences=True, activation=activation_funct))\n",
    "    if useDropout: model.add(Dropout(dropout))\n",
    "    model.add(GRU(50, return_sequences=False, activation=activation_funct))\n",
    "    model.add(Dense(1, activation=activation_funct))\n",
    "\n",
    "    optimizer = RMSprop(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss=loss)\n",
    "\n",
    "    return model, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build SuperLoovy Model\n",
    "\n",
    "# 6 LSTM layers with 50 inputs. Returns full sequence\n",
    "# 1 LSTM layer with 50 inputs. Does not return full sequence\n",
    "# 1 Dense layer with 1 input.\n",
    "# input -> 50 -> 50 -> 50 -> 50noFS ->1\n",
    "# Kernel Initializer: Glorot Uniform\n",
    "# Recurrent Initializer: Orthogonal\n",
    "# Bias Initializer: Zeros\n",
    "\n",
    "def build_super_loovy(useDropout = True):\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, return_sequences=True, activation=activation_funct))\n",
    "    if useDropout: model.add(Dropout(dropout))\n",
    "    model.add(LSTM(50, return_sequences=True, activation=activation_funct))\n",
    "    if useDropout: model.add(Dropout(dropout))\n",
    "    model.add(LSTM(50, return_sequences=True, activation=activation_funct))\n",
    "    if useDropout: model.add(Dropout(dropout))\n",
    "    model.add(LSTM(50, return_sequences=True, activation=activation_funct))\n",
    "    if useDropout: model.add(Dropout(dropout))\n",
    "    model.add(LSTM(50, return_sequences=True, activation=activation_funct))\n",
    "    if useDropout: model.add(Dropout(dropout))\n",
    "    model.add(LSTM(50, return_sequences=True, activation=activation_funct))\n",
    "    if useDropout: model.add(Dropout(dropout))\n",
    "    model.add(LSTM(50, return_sequences=False, activation=activation_funct))\n",
    "    model.add(Dense(1, activation=activation_funct))\n",
    "   \n",
    "    optimizer = RMSprop(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss=loss)\n",
    "\n",
    "    return model, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting methods\n",
    "def plot_results(preds, actual, title):\n",
    "    fig, ax = plt.subplots(figsize=(15,5))\n",
    "    ax.set_title(title)\n",
    "    time = range(len(preds))\n",
    "    ax.plot(time,preds,color='tab:red',marker='s',markersize=2,linestyle='-',linewidth=1,label='forcast')\n",
    "    ax.plot(time,actual,color='tab:blue',marker='s',markersize=2,linestyle='-',linewidth=1,label='actual')\n",
    "    ax.set_xlabel('time')\n",
    "    ax.set_ylabel('stock price ($)')\n",
    "    ax.set_xticks(np.arange(0,len(preds)+10,10))\n",
    "    ax.set_xlim(0,len(preds)+10)\n",
    "    ax.xaxis.grid(True,ls='--')\n",
    "    ax.yaxis.grid(True,ls='--')\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(f'../imgs/{title}.png', ext='png', bbox_inches=\"tight\")  \n",
    "\n",
    "colors = ['tab:red', 'tab:orange', 'tab:green', 'tab:purple', 'tab:pink', 'tab:cyan', 'tab:olive', 'tab:gray', 'tab:brown']\n",
    "def multi_plot_results(preds, actual, titles, title):\n",
    "    fig, ax = plt.subplots(figsize=(15,5))\n",
    "    ax.set_title(title)\n",
    "    time = range(len(actual))\n",
    "    for i in range(len(preds)):\n",
    "        ax.plot(time,preds[i],color=colors[i],marker='s',markersize=2,linestyle='-',linewidth=1,label=titles[i])\n",
    "    ax.plot(time,actual,color='tab:blue',marker='D',markersize=2,linestyle='-',linewidth=1,label='actual')\n",
    "    ax.set_xlabel('time')\n",
    "    ax.set_ylabel('stock price ($)')\n",
    "    ax.set_xticks(np.arange(0,len(actual)+10,10))\n",
    "    ax.set_xlim(0,len(actual)+10)\n",
    "    ax.xaxis.grid(True,ls='--')\n",
    "    ax.yaxis.grid(True,ls='--')\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(f'../imgs/{title}.png', ext='png', bbox_inches=\"tight\")\n",
    "\n",
    "multi_preds = []\n",
    "multi_titles = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "# Model Hyperparameters\n",
    "\n",
    "learning_rate = 0.001\n",
    "momentum = 0.9\n",
    "optimizer = RMSprop(learning_rate=learning_rate)\n",
    "loss = 'mean_absolute_percentage_error'\n",
    "activation_funct = 'elu'\n",
    "epochs = 100\n",
    "batch_size = 150\n",
    "dropout = 0.2\n",
    "\n",
    "# Data Columns parameter (defaults to 'high' for both)\n",
    "# Options: open high low close volume\n",
    "# train_data_columns = ['close', 'volume']\n",
    "# test_data_column = ['close']\n",
    "train_data_columns = ['high']\n",
    "test_data_column = ['high']\n",
    "\n",
    "# Length of days to split data on\n",
    "day_range = 60 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Prep - Get Data\n",
    "\n",
    "full_apple_train = get_stock_data(\"AAPL\", \"2003-02-10\", \"2004-09-12\")\n",
    "last_59_train = full_apple_train[-59:]\n",
    "part_apple_test = get_stock_data(\"AAPL\", \"2004-09-13\", \"2005-01-22\")\n",
    "full_apple_test = last_59_train.append(part_apple_test)\n",
    "\n",
    "full_ibm_train = get_stock_data(\"IBM\", \"2003-02-10\", \"2004-09-12\")\n",
    "last_59_train = full_ibm_train[-59:]\n",
    "part_ibm_test = get_stock_data(\"IBM\", \"2004-09-13\", \"2005-01-22\")\n",
    "full_ibm_test = last_59_train.append(part_ibm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Prep - Helper Methods\n",
    "\n",
    "# Extract high and normalize high data\n",
    "def data_prep(in_train_data, in_test_data, scaler, data_columns=['high']):\n",
    "    train_data = in_train_data[data_columns].values\n",
    "    # train_data = train_data.reshape(-1,1)\n",
    "    train_scale = scaler.fit_transform(train_data)\n",
    "\n",
    "    test_data = in_test_data[data_columns].values\n",
    "    # test_data = test_data.reshape(-1,1)\n",
    "    test_scale = scaler.transform(test_data)\n",
    "\n",
    "    return train_scale, test_scale, scaler\n",
    "\n",
    "# Split train/test data into x/y sets\n",
    "# For single column i.e. like high only\n",
    "def get_xy_train_sets(train_data):\n",
    "    X_train = []\n",
    "    Y_train = []\n",
    "\n",
    "    for i in range(day_range, len(train_data)):\n",
    "        X_train.append(train_data[i-day_range:i, 0])\n",
    "        Y_train.append(train_data[i,0])\n",
    "\n",
    "    x_train, y_train = np.array(X_train), np.array(Y_train)\n",
    "    x_train = np.reshape(x_train, (*x_train.shape, 1))\n",
    "\n",
    "    return x_train, y_train\n",
    "\n",
    "def get_xy_test_sets(scaled_test_data, raw_test_data, data_column='high'):\n",
    "    X_test = []\n",
    "    for i in range(day_range, len(scaled_test_data)):\n",
    "        X_test.append(scaled_test_data[i-day_range:i, 0])\n",
    "\n",
    "    x_test = np.array(X_test)\n",
    "    x_test = np.reshape(x_test, (*x_test.shape, 1))\n",
    "\n",
    "    test_data = raw_test_data[data_column].values\n",
    "    \n",
    "    Y_test = []\n",
    "    for i in range(day_range, len(test_data)):\n",
    "        Y_test.append(test_data[i])\n",
    "    \n",
    "    y_test = np.array(Y_test)\n",
    "\n",
    "    return x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, predict methods\n",
    "\n",
    "def train(model, in_epochs, in_batch_size):\n",
    "    model.fit(x_train, y_train, epochs=in_epochs, batch_size=in_batch_size)\n",
    "    return model\n",
    "\n",
    "def predict(model, x_test, scaler):\n",
    "    scaled_predictions = model.predict(x_test)\n",
    "\n",
    "    # https://stackoverflow.com/questions/42997228/lstm-keras-error-valueerror-non-broadcastable-output-operand-with-shape-67704\n",
    "    fitted_scaled_predictions = np.zeros(shape=(len(scaled_predictions), len(train_data_columns)))\n",
    "    fitted_scaled_predictions[:,0] = scaled_predictions[:,0]\n",
    "    test_predictions = scaler.inverse_transform(fitted_scaled_predictions )[:,0]\n",
    "\n",
    "    return test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apple\n",
    "print('Starting Simple RNN MAPE - Apple using ', train_data_columns)\n",
    "rnn, scaler = build_simple_rnn(len(train_data_columns))\n",
    "\n",
    "train_scale, test_scale, scaler = data_prep(full_apple_train, full_apple_test, scaler, train_data_columns)\n",
    "x_train, y_train = get_xy_train_sets(train_scale)\n",
    "x_test, y_test = get_xy_test_sets(test_scale, full_apple_test, test_data_column)\n",
    "\n",
    "rnn = train(rnn, epochs, batch_size)\n",
    "y_preds = predict(rnn, x_test, scaler)\n",
    "\n",
    "plot_results(y_preds, y_test, 'Simple RNN MAPE - Apple using ' + str(test_data_column))\n",
    "\n",
    "multi_preds.append(y_preds)\n",
    "multi_titles.append('SimpleRNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apple\n",
    "print('Starting Groovy RNN MAPE - Apple using ', train_data_columns)\n",
    "rnn, scaler = build_groovy()\n",
    "\n",
    "train_scale, test_scale, scaler = data_prep(full_apple_train, full_apple_test, scaler, train_data_columns)\n",
    "x_train, y_train = get_xy_train_sets(train_scale)\n",
    "x_test, y_test = get_xy_test_sets(test_scale, full_apple_test)\n",
    "\n",
    "rnn = train(rnn, epochs, batch_size)\n",
    "y_preds = predict(rnn, x_test, scaler)\n",
    "\n",
    "plot_results(y_preds, y_test, 'Groovy MAPE - Apple using ' + str(test_data_column))\n",
    "\n",
    "multi_preds.append(y_preds)\n",
    "multi_titles.append('Groovy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apple\n",
    "print('Starting Loovy RNN MAPE - Apple using ', train_data_columns)\n",
    "rnn, scaler = build_loovy()\n",
    "\n",
    "train_scale, test_scale, scaler = data_prep(full_apple_train, full_apple_test, scaler, train_data_columns)\n",
    "x_train, y_train = get_xy_train_sets(train_scale)\n",
    "x_test, y_test = get_xy_test_sets(test_scale, full_apple_test)\n",
    "\n",
    "rnn = train(rnn, epochs, batch_size)\n",
    "y_preds = predict(rnn, x_test, scaler)\n",
    "\n",
    "plot_results(y_preds, y_test, 'Loovy MAPE - Apple using ' + str(test_data_column))\n",
    "\n",
    "# multi_preds.append(y_preds)\n",
    "# multi_titles.append('Loovy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apple\n",
    "print('Starting Super Groovy RNN MAPE - Apple using ', train_data_columns)\n",
    "rnn, scaler = build_super_groovy()\n",
    "\n",
    "train_scale, test_scale, scaler = data_prep(full_apple_train, full_apple_test, scaler, train_data_columns)\n",
    "x_train, y_train = get_xy_train_sets(train_scale)\n",
    "x_test, y_test = get_xy_test_sets(test_scale, full_apple_test)\n",
    "\n",
    "rnn = train(rnn, epochs, batch_size)\n",
    "y_preds = predict(rnn, x_test, scaler)\n",
    "\n",
    "plot_results(y_preds, y_test, 'Super Groovy MAPE - Apple using ' + str(test_data_column))\n",
    "\n",
    "multi_preds.append(y_preds)\n",
    "multi_titles.append('SGroovy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apple\n",
    "print('Starting Super Loovy RNN MAPE - Apple using ', train_data_columns)\n",
    "rnn, scaler = build_super_loovy()\n",
    "\n",
    "train_scale, test_scale, scaler = data_prep(full_apple_train, full_apple_test, scaler, train_data_columns)\n",
    "x_train, y_train = get_xy_train_sets(train_scale)\n",
    "x_test, y_test = get_xy_test_sets(test_scale, full_apple_test)\n",
    "\n",
    "rnn = train(rnn, epochs, batch_size)\n",
    "y_preds = predict(rnn, x_test, scaler)\n",
    "\n",
    "plot_results(y_preds, y_test, 'Super Loovy MAPE - Apple using ' + str(test_data_column))\n",
    "\n",
    "# multi_preds.append(y_preds)\n",
    "# multi_titles.append('SLoovy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_plot_results(multi_preds, y_test, multi_titles, 'Apple using ' + str(test_data_column))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_preds = []\n",
    "multi_titles = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IBM\n",
    "print('Starting Simple RNN MAPE - IBM using ', train_data_columns)\n",
    "rnn, scaler = build_simple_rnn()\n",
    "\n",
    "train_scale, test_scale, scaler = data_prep(full_ibm_train, full_ibm_test, scaler, train_data_columns)\n",
    "x_train, y_train = get_xy_train_sets(train_scale)\n",
    "x_test, y_test = get_xy_test_sets(test_scale, full_ibm_test)\n",
    "\n",
    "rnn = train(rnn, epochs, batch_size)\n",
    "y_preds = predict(rnn, x_test, scaler)\n",
    "\n",
    "plot_results(y_preds, y_test, 'Simple RNN MAPE - IBM using ' + str(test_data_column))\n",
    "\n",
    "multi_preds.append(y_preds)\n",
    "multi_titles.append('SimpleRNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IBM\n",
    "print('Starting Groovy RNN MAPE - IBM using ', train_data_columns)\n",
    "rnn, scaler = build_groovy()\n",
    "\n",
    "train_scale, test_scale, scaler = data_prep(full_ibm_train, full_ibm_test, scaler, train_data_columns)\n",
    "x_train, y_train = get_xy_train_sets(train_scale)\n",
    "x_test, y_test = get_xy_test_sets(test_scale, full_ibm_test)\n",
    "\n",
    "rnn = train(rnn, epochs, batch_size)\n",
    "y_preds = predict(rnn, x_test, scaler)\n",
    "\n",
    "plot_results(y_preds, y_test, 'Groovy MAPE - IBM using ' + str(test_data_column))\n",
    "\n",
    "multi_preds.append(y_preds)\n",
    "multi_titles.append('Groovy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IBM\n",
    "print('Starting Loovy RNN MAPE - IBM using ', train_data_columns)\n",
    "rnn, scaler = build_loovy()\n",
    "\n",
    "train_scale, test_scale, scaler = data_prep(full_ibm_train, full_ibm_test, scaler, train_data_columns)\n",
    "x_train, y_train = get_xy_train_sets(train_scale)\n",
    "x_test, y_test = get_xy_test_sets(test_scale, full_ibm_test)\n",
    "\n",
    "rnn = train(rnn, epochs, batch_size)\n",
    "y_preds = predict(rnn, x_test, scaler)\n",
    "\n",
    "plot_results(y_preds, y_test, 'Loovy MAPE - IBM using ' + str(test_data_column))\n",
    "\n",
    "multi_preds.append(y_preds)\n",
    "multi_titles.append('Loovy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IBM\n",
    "print('Starting Super Groovy RNN MAPE - IBM using ', train_data_columns)\n",
    "rnn, scaler = build_super_groovy()\n",
    "\n",
    "train_scale, test_scale, scaler = data_prep(full_ibm_train, full_ibm_test, scaler, train_data_columns)\n",
    "x_train, y_train = get_xy_train_sets(train_scale)\n",
    "x_test, y_test = get_xy_test_sets(test_scale, full_ibm_test)\n",
    "\n",
    "rnn = train(rnn, epochs, batch_size)\n",
    "y_preds = predict(rnn, x_test, scaler)\n",
    "\n",
    "plot_results(y_preds, y_test, 'Super Groovy MAPE - IBM using ' + str(test_data_column))\n",
    "\n",
    "multi_preds.append(y_preds)\n",
    "multi_titles.append('SGroovy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IBM\n",
    "print('Starting Super Loovy RNN MAPE - IBM using ', train_data_columns)\n",
    "rnn, scaler = build_super_loovy()\n",
    "\n",
    "train_scale, test_scale, scaler = data_prep(full_ibm_train, full_ibm_test, scaler, train_data_columns)\n",
    "x_train, y_train = get_xy_train_sets(train_scale)\n",
    "x_test, y_test = get_xy_test_sets(test_scale, full_ibm_test)\n",
    "\n",
    "rnn = train(rnn, epochs, batch_size)\n",
    "y_preds = predict(rnn, x_test, scaler)\n",
    "\n",
    "plot_results(y_preds, y_test, 'Super Loovy MAPE - IBM using ' + str(test_data_column))\n",
    "\n",
    "multi_preds.append(y_preds)\n",
    "multi_titles.append('SLoovy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_plot_results(multi_preds, y_test, multi_titles, 'IBM using ' + str(test_data_column))"
   ]
  }
 ]
}